# Monte Carlo sampling parameters for the AI Futures Simulator
# Based on the ai_takeoff_model sampling configuration
#
# Each parameter can be:
#   - A point estimate: r_software: 2.4
#   - A distribution: r_software: {dist: uniform, min: 2.0, max: 3.0}
#
# Supported distributions:
#   - fixed: {dist: fixed, value: 2.4}
#   - uniform: {dist: uniform, min: 2.0, max: 3.0}
#   - normal: {dist: normal, ci80: [low, high]} or {dist: normal, mean: 0.6, sd: 0.05}
#   - lognormal: {dist: lognormal, ci80: [low, high]}
#   - shifted_lognormal: {dist: shifted_lognormal, ci80: [low, high], shift: 1.0}
#   - beta: {dist: beta, alpha: 2, beta: 3, min: 0, max: 1}
#   - choice: {dist: choice, values: [-5, -2, -1], p: [0.25, 0.5, 0.25]}

time_range: [2025.0, 2040.0]
initial_progress: 0.0
seed: 42

parameters:
  # =========================================================================
  # HORIZON / MILESTONE PARAMETERS
  # =========================================================================
  # Superhuman coder time horizon (minutes)
  # ci80: [0.1 work year, 225,000 work years]
  ac_time_horizon_minutes:
    dist: lognormal
    ci80: [12456, 28000000000]
    min: 960  # At least 16 hours (longest METR tasks)

  horizon_extrapolation_type: "decaying doubling time"

  # Pre-gap AC horizon (minutes)
  # ci80: [0.1 work year, 10 work years]
  pre_gap_ac_time_horizon:
    dist: lognormal
    ci80: [12456, 1245600]
    min: 26  # At least GPT-5's horizon

  # Gap mode
  include_gap:
    dist: choice
    values: ["no gap", "gap"]
    p: [0.55, 0.45]

  gap_years:
    dist: lognormal
    ci80: [0.3, 7.5]
    min: 0.0

  # Manual horizon fitting
  present_day: 2025.6
  present_horizon: 26.0

  present_doubling_time:
    dist: lognormal
    ci80: [0.29, 0.717]
    min: 0.0

  doubling_difficulty_growth_factor:
    dist: normal
    ci80: [0.82, 1.02]
    min: 0.6
    max: 1.02

  # =========================================================================
  # PRODUCTION FUNCTION PARAMETERS (CES)
  # =========================================================================
  # Coding labor elasticity
  rho_coding_labor:
    dist: choice
    values: [-5, -2, -1]
    p: [0.25, 0.5, 0.25]

  coding_labor_normalization: 1.0

  # Experiment capacity
  rho_experiment_capacity: -0.155
  alpha_experiment_capacity: 0.777
  experiment_compute_exponent: 0.655

  # Experiment capacity asymptotes
  inf_compute_asymptote:
    dist: shifted_lognormal
    ci80: [25, 40000]
    shift: 1.0
    min: 1.0

  inf_labor_asymptote:
    dist: shifted_lognormal
    ci80: [1, 200]
    shift: 1.0
    min: 1.0

  inv_compute_anchor_exp_cap:
    dist: shifted_lognormal
    ci80: [0.8, 5.3]
    shift: 1.0
    min: 1.0
    max: 10

  parallel_penalty:
    dist: beta
    alpha: 3
    beta: 3
    min: 0.0
    max: 1.0

  # =========================================================================
  # SOFTWARE PROGRESS PARAMETERS
  # =========================================================================
  r_software: 2.40

  software_progress_rate_at_reference_year:
    dist: lognormal
    ci80: [0.4, 2.5]

  # =========================================================================
  # AUTOMATION SCHEDULE PARAMETERS
  # =========================================================================
  automation_fraction_at_coding_automation_anchor: 1.0
  automation_interp_type: "linear"
  automation_logistic_asymptote: 1.05

  swe_multiplier_at_present_day:
    dist: shifted_lognormal
    ci80: [0.18, 2]
    shift: 1.0
    min: 1.0

  coding_labor_mode: "optimal_ces"

  coding_automation_efficiency_slope:
    dist: lognormal
    ci80: [0.67, 6]
    min: 0.1

  max_serial_coding_labor_multiplier:
    dist: lognormal
    ci80: [10000, 1000000000000]
    min: 1.0

  optimal_ces_eta_init: 0.05
  optimal_ces_grid_size: 4096
  optimal_ces_frontier_tail_eps: 0.000001
  optimal_ces_frontier_cap: 1000000000000.0

  # =========================================================================
  # AI RESEARCH TASTE PARAMETERS
  # =========================================================================
  ai_research_taste_at_coding_automation_anchor_sd:
    dist: normal
    ci80: [-2.5, 3.5]
    clip_to_bounds: false

  ai_research_taste_slope:
    dist: lognormal
    ci80: [0.7, 6.9]
    clip_to_bounds: false

  taste_schedule_type: "SDs per progress-year"

  median_to_top_taste_multiplier:
    dist: shifted_lognormal
    ci80: [0.7, 10.4]
    shift: 1.0
    clip_to_bounds: false

  top_percentile: 0.999

  taste_limit:
    dist: lognormal
    ci80: [2, 32]
    clip_to_bounds: false

  taste_limit_smoothing:
    dist: beta
    alpha: 2
    beta: 2
    clip_to_bounds: false

  # Capability milestones
  strat_ai_m2b: 2.0

  ted_ai_m2b:
    dist: lognormal
    ci80: [1, 9]
    min: 0

  # =========================================================================
  # TRAINING COMPUTE GROWTH PARAMETERS
  # =========================================================================
  constant_training_compute_growth_rate:
    dist: normal
    ci80: [0.55, 0.65]
    min: 0.0

  slowdown_year:
    dist: uniform
    min: 2026.0
    max: 2030.0

  post_slowdown_training_compute_growth_rate:
    dist: normal
    ci80: [0.15, 0.35]
    min: 0.0

  # =========================================================================
  # MODE FLAGS (fixed for standard runs)
  # =========================================================================
  update_software_progress: true
  sos_mode: false
  plan_a_mode: false
  is_blacksite: false

  # =========================================================================
  # INITIAL CONDITIONS
  # =========================================================================
  initial_compute_tpp_h100e: 100000.0
  initial_human_researchers: 1000

# =========================================================================
# CORRELATION MATRIX (optional)
# =========================================================================
# Creates correlations between related parameters using Spearman rank correlation
correlation_matrix:
  parameters:
    - "present_doubling_time"
    - "doubling_difficulty_growth_factor"
    - "ai_research_taste_slope"
    - "ai_research_taste_at_coding_automation_anchor_sd"
    - "gap_years"
    - "pre_gap_ac_time_horizon"
    - "slowdown_year"
    - "ac_time_horizon_minutes"
    - "coding_automation_efficiency_slope"
    - "inv_compute_anchor_exp_cap"
    - "inf_compute_asymptote"
  correlation_matrix:
    # present_doubling_time
    - [ 1.00,  0.60, -0.30,  0.00,  0.00,  0.00, -0.30,  0.00, -0.15,  0.00,  0.00]
    # doubling_difficulty_growth_factor
    - [ 0.60,  1.00, -0.30,  0.00,  0.30, -0.50,  0.00, -0.50, -0.10,  0.00,  0.00]
    # ai_research_taste_slope
    - [-0.30, -0.30,  1.00,  0.30,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00]
    # ai_research_taste_at_coding_automation_anchor_sd
    - [ 0.00,  0.00,  0.30,  1.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00]
    # gap_years
    - [ 0.00,  0.30,  0.00,  0.00,  1.00, -0.70, -0.30,  0.00,  0.00,  0.00,  0.00]
    # pre_gap_ac_time_horizon
    - [ 0.00, -0.50,  0.00,  0.00, -0.70,  1.00,  0.00,  0.00,  0.00,  0.00,  0.00]
    # slowdown_year
    - [-0.30,  0.00,  0.00,  0.00, -0.30,  0.00,  1.00, -0.30,  0.00,  0.00,  0.00]
    # ac_time_horizon_minutes
    - [ 0.00, -0.50,  0.00,  0.00,  0.00,  0.00, -0.30,  1.00,  0.00,  0.00,  0.00]
    # coding_automation_efficiency_slope
    - [-0.15, -0.10,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  1.00,  0.00,  0.00]
    # inv_compute_anchor_exp_cap
    - [ 0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  1.00,  0.50]
    # inf_compute_asymptote
    - [ 0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.50,  1.00]
  correlation_type: "spearman"

# =========================================================================
# COMPUTE PARAMETERS WITH UNCERTAINTY
# =========================================================================
compute:
  prc_compute:
    # Annual growth rate of PRC compute stock
    # Reference model uses metalog distribution with p10=1.3, p50=2.2, p90=3.0
    annual_growth_rate_of_prc_compute_stock:
      dist: metalog
      p10: 1.3
      p50: 2.2
      p90: 3.0
    # Scanner productivity: wafers produced per lithography scanner per month
    # Discrete model: median=1000, relative_sigma=0.20
    wafers_per_month_per_lithography_scanner:
      dist: lognormal
      ci80: [776, 1288]

    # Construction time for small fab (5k wafers/month capacity)
    # These are deterministic reference points; uncertainty is applied via fab_construction_time_multiplier
    construction_time_for_5k_wafers_per_month: 1.40

    # Construction time for large fab (100k wafers/month capacity)
    construction_time_for_100k_wafers_per_month: 2.41

    # Fab construction time multiplier - applies uncertainty to computed duration
    # Discrete model: relative_sigma=0.35 applied to computed duration
    # CI80 calculated from lognormal with relative_sigma=0.35: [0.64, 1.56]
    fab_construction_time_multiplier:
      dist: lognormal
      ci80: [0.64, 1.56]

    # PRC lithography scanner production in first year
    # Discrete model: median=20, relative_sigma=0.30
    prc_lithography_scanners_produced_in_first_year:
      dist: lognormal
      ci80: [13.7, 29.2]

    # Additional PRC lithography scanners produced per year after first year
    # Discrete model: median=16, relative_sigma=0.30
    prc_additional_lithography_scanners_produced_per_year:
      dist: lognormal
      ci80: [11.0, 23.3]

    # Labor productivity: wafers produced per operating worker per month (for black projects)
    # Discrete model: median=24.64, relative_sigma=0.62
    fab_wafers_per_month_per_operating_worker:
      dist: lognormal
      ci80: [11.9, 51.2]

# =========================================================================
# DATACENTER AND ENERGY PARAMETERS WITH UNCERTAINTY
# =========================================================================
datacenter_and_energy:
  prc_energy_consumption:
    # Datacenter construction productivity: MW of capacity per worker per year
    # Discrete model: median=0.13, relative_sigma=0.40
    data_center_mw_per_year_per_construction_worker:
      dist: lognormal
      ci80: [0.079, 0.213]

    # Datacenter operating labor: MW of capacity per operating worker
    # Discrete model: median=1.0 (1 worker per MW), relative_sigma=0.40
    data_center_mw_per_operating_worker:
      dist: lognormal
      ci80: [0.61, 1.64]

# =========================================================================
# BLACK PROJECT PARAMETERS WITH UNCERTAINTY
# =========================================================================
black_project:
  properties:
    # PRC localization years - separate distributions for each process node
    # Based on reference model: linear interpolation from 0% at 2025 to X% at 2031
    # 28nm: 25% by 2031, 14nm: 10% by 2031, 7nm: 6% by 2031

    # 28nm localization: 25% probability by 2031
    prc_localization_year_28nm:
      dist: choice
      values: [2026, 2027, 2028, 2029, 2030, 2031, 9999]
      p: [0.042, 0.042, 0.042, 0.042, 0.042, 0.042, 0.748]

    # 14nm localization: 10% probability by 2031
    prc_localization_year_14nm:
      dist: choice
      values: [2026, 2027, 2028, 2029, 2030, 2031, 9999]
      p: [0.017, 0.017, 0.017, 0.017, 0.017, 0.017, 0.898]

    # 7nm localization: 6% probability by 2031
    prc_localization_year_7nm:
      dist: choice
      values: [2026, 2027, 2028, 2029, 2030, 2031, 9999]
      p: [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.94]

    # Fraction of lithography scanners to divert (fixed 10% to match reference model)
    fraction_of_lithography_scanners_to_divert_at_black_project_start: 0.10
